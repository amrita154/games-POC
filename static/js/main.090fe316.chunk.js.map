{"version":3,"sources":["logo.svg","components/speech-game/data.js","components/speech-game/index.js","App.js","reportWebVitals.js","index.js"],"names":["gameData","id","object","action","animation","require","SpeechToText","useSpeechRecognition","transcript","resetTranscript","containerRef","useRef","useState","setId","useEffect","lottie","loadAnimation","container","current","animationData","loop","autoplay","name","stop","console","log","temp","split","length","toLowerCase","play","pause","SpeechRecognition","browserSupportsSpeechRecognition","alert","startListening","continuous","stopListening","ref","style","height","width","onClick","destroy","App","reportWebVitals","onPerfEntry","Function","then","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"qtymBAAe,I,6CCsBAA,EAtBA,CACX,CACIC,GAAG,EACHC,OAAO,OACPC,OAAO,MACPC,UAAUC,EAAQ,KAGtB,CACIJ,GAAG,EACHC,OAAO,QACPC,OAAO,OACPC,UAAUC,EAAQ,KACpB,CACGJ,GAAG,EACJC,OAAO,OACPC,OAAO,iBACPC,UAAUC,EAAQ,M,OCoDXC,EA9DM,WAAO,IAAD,EACeC,iCAAhCC,EADiB,EACjBA,WAAYC,EADK,EACLA,gBACdC,EAAeC,iBAAO,MAFH,EAGRC,mBAAS,GAHD,mBAGlBX,EAHkB,KAGfY,EAHe,KAoDzB,OApCAC,qBAAU,WAQN,OAPFC,IAAOC,cAAc,CACnBC,UAAWP,EAAaQ,QACxBC,cAAenB,EAASC,GAAIG,UAC5BgB,MAAK,EACLC,UAAS,EACTC,KAAK,cAEE,kBAAMP,IAAOQ,UACtB,CAACtB,IAEHa,qBAAU,WACNU,QAAQC,IAAI,aAAajB,GACzB,IAAIkB,GACLA,EAAKlB,EAAWmB,MAAM,MACdD,EAAKE,OAAO,KAAK5B,EAASC,GAAIC,OAAO2B,eAAeH,EAAKA,EAAKE,OAAO,KAAK5B,EAASC,GAAIC,OAC9Fa,IAAOe,KAAK,cAEZf,IAAOgB,MAAM,aACbtB,OAED,CAACD,EAAWP,IAEfa,qBAAU,WAMR,OALKkB,IAAkBC,oCACrBC,MAAM,+CAERF,IAAkBG,eAAe,CAAEC,YAAY,IAC/CZ,QAAQC,IAAI,oBACL,WACLO,IAAkBK,gBAClBb,QAAQC,IAAI,wBAEb,IAID,gCACE,yCAAYzB,EAASC,GAAIC,OAAzB,OAAqCF,EAASC,GAAIE,UAClD,6BAAKK,IACL,qBAAKP,GAAG,YAAYqC,IAAK5B,EAAc6B,MAAO,CAACC,OAAO,MAAMC,MAAM,SAClE,wBAAQC,QApDM,WAEV7B,EADDZ,EAAG,EACIA,EAAG,EAGH,GAEVQ,IACAM,IAAO4B,QAAQ,cA4Cf,sBCtDSC,MANf,WACE,OACE,cAAC,EAAD,KCMWC,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,6BAAqBC,MAAK,YAAkD,IAA/CC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAQP,OCDdQ,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1Bb,M","file":"static/js/main.090fe316.chunk.js","sourcesContent":["export default __webpack_public_path__ + \"static/media/logo.6ce24c58.svg\";","const gameData=[\n    {\n        id:1,\n        object:\"Bird\",\n        action:\"fly\",\n        animation:require('./../../assets/animation/flappy-bird-delivering-a-message.json'),\n\n    },\n    {\n        id:2,\n        object:\"Tiger\",\n        action:\"move\",\n        animation:require('./../../assets/animation/lion-running.json'),\n    },{\n         id:3,\n        object:\"Rain\",\n        action:\"start rainfall\",\n        animation:require('./../../assets/animation/rain-animation-with-umbrella.json'),\n    }\n]\n\n\nexport default gameData;","import React, { useEffect, useRef, useState } from \"react\";\nimport lottie from \"lottie-web\";\nimport SpeechRecognition, {\n  useSpeechRecognition,\n} from \"react-speech-recognition\";\nimport gameData from './data';\n\nconst SpeechToText = () => {\n  const { transcript, resetTranscript } = useSpeechRecognition();\n  const containerRef = useRef(null);\n  const [id,setId]=useState(0);\n\n  const onPressNext=()=>{\n      if(id<2){\n          setId(id+1);\n      }\n      else{\n          setId(0);\n      }\n      resetTranscript();\n      lottie.destroy(\"animation\");\n  }\n\n  useEffect(() => {\n    lottie.loadAnimation({\n      container: containerRef.current,\n      animationData: gameData[id].animation,\n      loop:true,\n      autoplay:true,\n      name:\"animation\"\n    });\n      return () => lottie.stop();\n  },[id]);\n\n  useEffect(() => {\n      console.log(\"transcript\",transcript);\n      let temp=[];\n     temp=transcript.split(' ');\n    if (temp[temp.length-1]===gameData[id].object.toLowerCase()||temp[temp.length-1]===gameData[id].object) {\n      lottie.play(\"animation\");\n    } else {\n      lottie.pause(\"animation\");\n      resetTranscript();\n    }\n  }, [transcript,id]);\n\n  useEffect(() => {\n    if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n      alert(\"Browser does not support speech recognition\");\n    }\n    SpeechRecognition.startListening({ continuous: true });\n    console.log(\"Now listening...\");\n    return () => {\n      SpeechRecognition.stopListening();\n      console.log(\"Stopped Listening\");\n    };\n  }, []);\n\n\n  return (\n    <div>\n      <h1> Speak {gameData[id].object} to {gameData[id].action}</h1>\n      <h3>{transcript}</h3>\n      <div id=\"animation\" ref={containerRef} style={{height:'40%',width:'40%'}}/>\n      <button onClick={onPressNext}>Next</button>\n    </div>\n  );\n};\n\nexport default SpeechToText;\n","import logo from './logo.svg';\nimport './App.css';\nimport SpeechToText from './components/speech-game';\n\nfunction App() {\n  return (\n    <SpeechToText></SpeechToText>\n  );\n}\n\nexport default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}